%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ISE Lab -- Topic
% Giovanni Ciatto
% Alma Mater Studiorum - Universit√† di Bologna
% mailto:giovanni.ciatto@unibo.it
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\documentclass[handout]{beamer}\mode<handout>{\usetheme{default}}
%
\documentclass[presentation]{beamer}\mode<presentation>{\usetheme{AMSBolognaFC}}
%\documentclass[handout]{beamer}\mode<handout>{\usetheme{AMSBolognaFC}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{ise-lab-common}
\usepackage{psyki-tutorial}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\title[SKI via \psyki{}]{Symbolic Knowledge Injection via \psyki{}}
%
\subtitle{A tutorial}
%
\author[\sspeaker{\gcShort} et al.]{
    \speaker{\gcFull} \and Matteo Magnini
    \\
    \gcEmail \and \ttemail{matteo.magnini@unibo.it}
}
%
\institute[\uniboShort]{
    \disi{} (\disiShort)\\\unibo, Cesena, Italy
}
%
\date[PRIMA 2022]{
    $24^{th}$ International Conference on 
    \\
    Principles and Practice of Multi-Agent Systems
    \\
    November 16, 2022
}
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%/////////
\frame{\titlepage}
%/////////

%%===============================================================================
\section*{Outline}
%%===============================================================================
%
%%/////////
\frame[c]{\tableofcontents[hideallsubsections]}
%%/////////

%===============================================================================
\section{What and Why}
%===============================================================================

\begin{frame}%[allowframebreaks]
    \frametitle{What}

    \alert{\psyki}: a (Python) platform for symbolic knowledge injection

    \begin{columns}
        \begin{column}{.3\linewidth}
            \centering
            \includegraphics[width=\linewidth]{./figures/psyki-logo.pdf}
        \end{column}
        \begin{column}{.7\linewidth}
            \begin{block}{GitHub Repository}\centering
                \alert{\url{https://github.com/psykei/psyki-python}}

                \tiny{(please star us :)}
            \end{block}

            \begin{block}{Main papers}
                \begin{itemize}
                    \item TODO
                \end{itemize}
            \end{block}
        \end{column}
    \end{columns}
\end{frame}

% \begin{frame}[c]{Why}
%     \begin{itemize}
%         \item Pervasive adoption of \alert{sub-symbolic}, ML-based predictors in AI
        
%         \vfill

%         \item Their \alert{opacity}\ccite{Lipton2018} brings \alert{drawbacks}\ccite{guidotti2018survey}:
%         %
%         \vfill
%         %
%         \begin{itemize}\small
%             \item difficulty in \alert{spotting} unintendedly learnt knowledge
            
%             \vfill
            
%             \item difficulty in spotting ``\alert{bugs}'' in what a numeric predictor has learnt
            
%             \vfill
            
%             \item difficult to learn upon \alert{lacking data} 
                        
%             \vfill
            
%             \item difficult to transfer \alert{human's common-sense} to sub-symbolic AI
            
%         \end{itemize}

%         \vfill

%         \item[$\rightarrow$] Need to \alert{make} ML predictors \alert{predictable}
%         %
%         \begin{itemize}
%             \item by finely \alert{controlling} what that learn
%         \end{itemize}
%     \end{itemize}
% \end{frame}

%/////////
\begin{frame}[c]{Why SKI?}
    %
    There are several benefits:
    %
    \begin{itemize}
        %
        \item prevent the predictor to become a black-box\alert{!};
        %
        \item reduce learning time;
        %
        \item reduce the data size needed for training;
        %
        \item improve predictor's accuracy;
        %
        \item build a predictor that behave as a logic engine.
    \end{itemize}
    %
\end{frame}
%/////////

%===============================================================================
\section{Background}
%===============================================================================

\begin{frame}[allowframebreaks]{Symbolic Knowledge Injection}
    Key insights:
    %
    \medskip
    %
    \begin{itemize}
        \item \alert{Altering} ML predictors\ldots
        \medskip
        \item \ldots to make they \alert{comply} to user-provided knowledge\ldots
        \medskip
        \item \ldots which is represented in \alert{symbolic form}
    \end{itemize}

    \framebreak

    \begin{block}{We define SKI as:}
        any \alert{algorithmic} procedure affecting how \alert{sub-symbolic predictors} draw their inferences in such a way that predictions are either \alert{computed} as a function of, or made \alert{consistent} with, some \alert{given} \alert{symbolic knowledge}*.
    \end{block}
    %
    \bigskip
    %
    * a wide definition that includes the vast majority of the works surveyed in \cite{surveyNeuroSymb,surveyXie,surveyCalegariCO20}.

    \framebreak

    General workflow:
    %
    \begin{figure}
        \centering
        \includegraphics[width=0.8\textheight]{figures/ski-workflow.pdf}
    \end{figure}
\end{frame}

\begin{frame}[allowframebreaks]{What does `symbolic' actually mean?}
    According to \cite{Gelder90}, \alert{symbolic} representations of knowledge
    %
    \begin{itemize}
        \item involves a \alert{set of symbols},
        \item which can be combined (e.g., concatenated) in (possibly) \alert{infinitely many} ways, 
        \item following precise \alert{syntactical} rules, and
        \item where both elementary symbols and any admissible combination of them can be assigned with \alert{meaning}
        %
        \begin{itemize}
            \item[ie] \alert{each} symbol can be mapped into some entity from the domain at hand.
        \end{itemize}
    \end{itemize}
    
    \begin{exampleblock}{Notable example}
        \begin{itemize}
            \item formal logic
        \end{itemize}
    \end{exampleblock}

    \framebreak

    \begin{alertblock}{Opposite notion: \textbf{distributed} representations}
        \begin{itemize}
            \item where symbols \alert{alone} have no meaning
            \item unless it is considered along with its \alert{neighbourhood}
            %
            \begin{itemize}
                \item[ie] any other symbol which is \alert{close} (according to some notion of closeness)
            \end{itemize}
        \end{itemize}
    \end{alertblock}
\end{frame}

% \begin{frame}[allowframebreaks]{Plenty of SKI methods from the literature}
%     \input{tables/ski.tex}
% \end{frame}

\begin{frame}[allowframebreaks]{Taxonomy of SKI methods}
    \begin{center}
        \includegraphics[width=\linewidth]{figures/ski-taxonomy.pdf}
    \end{center}
    
    \framebreak

    \begin{description}
        \item[input knowledge] how is the knowledge to-be-injected represented?
        %
        \begin{itemize}
            \item commonly, some sub-set of first-order logic (FOL)
        \end{itemize} 

        \item[target predictor] which predictors can knowledge be injected into?
        %
        \begin{itemize}
            \item mostly, neural networks
        \end{itemize} 

        \item[strategy] how does injection actually work?
        %
        \begin{description}
            \item[structuring] todo describe
            \item[guided learning] todo describe
            \item[embedding] todo describe
        \end{description} 

        \item[purpose] why is knowledge injected in the first place?
        %
        \begin{description}
            \item[knowledge manipulation] todo describe
            \item[learning support] todo describe
        \end{description} 

    \end{description}
\end{frame}

\subsection{Focus on strategy}

%/////////
\begin{frame}[allowframebreaks]{Constraining}
    %
    \begin{itemize}
        \item Knowledge cost factor is introduced in the loss function;
        %
        \item for NN the cost affects backpropagation \ccite{backpropagation} during training.
        %
        \begin{itemize}
            \item[$\Rightarrow$] Predictor does not violate the prior knowledge (to a certain extent).
        \end{itemize} 
    \end{itemize}
    
    \begin{figure}
        \centering
        \includegraphics[width=0.6\textwidth]{figures/ski-constraining}
    \end{figure}
    %
    
    \framebreak
    
    \begin{figure}
        \centering
        \includegraphics[width=0.8\textwidth]{figures/nn-backprop.png}
    \end{figure}

    \framebreak

    \begin{figure}
        \centering
        \includegraphics[width=0.8\textwidth]{figures/nn-gradient-descent.png}
    \end{figure}    
\end{frame}
%/////////

%/////////
\begin{frame}[allowframebreaks]{Structuring}
    %
    \begin{itemize}
        \item Inner architecture is shaped to be able to ``mimic'' the knowledge;
        %
        \item for NN this means \emph{ad-hoc} layers.
        %
        \begin{itemize}
            \item[$\Rightarrow$] Predictor directly exploits knowledge when needed.
        \end{itemize} 
    \end{itemize}
    %
    \begin{figure}
        \centering
        \includegraphics[width=0.7\textwidth]{figures/ski-structuring}
    \end{figure}
    %
    
    \framebreak
    
   \begin{itemize}
       \item We need to define a mapping from crispy logic rules into fuzzy continuous interpretations;
       %
       \item then we need to map the interpretations into ad-hoc neurons/layers.
   \end{itemize}   

    \framebreak
    
    \begin{equation*}
        \begin{aligned}
            \var{A}&\leftarrow\var{B}\wedge\var{C}\wedge\neg\var{D}.\\
            \var{A}&\leftarrow\var{E}\wedge\var{F}.\\
            \var{B}&\leftarrow\const{true}.\\
        \end{aligned}    
    \end{equation*}
    %
    \begin{figure}
        \centering
        \includegraphics[height=0.5\textheight]{figures/structuring-example}
    \end{figure}
\end{frame}
%/////////

%/////////
\begin{frame}[allowframebreaks]{Embedding}
    %
    \begin{itemize}
        \item Symbolic knowledge is embedded into a tensor form;
        %
        \item this is used as predictor's input data (alone or with a ``standard'' dataset).
        %
        \begin{itemize}
            \item[$\Rightarrow$] Predictor's aim is manifold in most cases.
        \end{itemize} 
    \end{itemize}
    
    \begin{figure}
        \centering
        \includegraphics[width=0.7\textwidth]{figures/ski-embedding}
    \end{figure}
    %
    \framebreak
    %
    \begin{itemize}
        \item Knowledge graph embedding \ccite{kge-survey};
        %
        \item entities and relations are embedded into continuos vector spaces;
        %
        \item scoring function $f_{r}(h,t)$ defined on each fact $(h, r, t)$ to measure its plausibility;
    \end{itemize}
    %
    \begin{figure}
        \centering
        \includegraphics[width=0.8\textwidth]{figures/kge-space.png}
    \end{figure}

    \framebreak
    
    \begin{figure}
        \centering
        \includegraphics[width=0.8\textwidth]{figures/kge-nn-1.png}
    \end{figure}

    \begin{figure}
        \centering
        \includegraphics[width=0.8\textwidth]{figures/kge-nn-2.png}
    \end{figure}
    
\end{frame}
%/////////

\subsection{Focus on input knowledge}

%/////////
\begin{frame}[allowframebreaks]{Logic}
    \begin{block}{Intensional}
        \begin{itemize}
            \item indirect representation of data,
            %
            \item define a relation/set by describing its elements via other relations/sets.
        \end{itemize}
        %
    \end{block}
    %
    \begin{block}{Extensional}
        \begin{itemize}
            \item direct representation of data,
            %
            \item explicit definition of entities involved.
        \end{itemize}
    \end{block}
    
    Recursive intensional predicates are very expressive and powerful, as they enable the description of infinite sets via a finite (and commonly small) amount of formul\ae.
    
    \framebreak        
    
    Almost the totality of SKI algorithms deal with:
    %
    \begin{itemize}
        \item \alert{first order logic} (FOL);
        %
        \item \alert{knowledge graph} (KG);
        %
        \item \alert{propositional logic} (PL).
        
    \end{itemize}
\end{frame}
%/////////
    
%/////////
\begin{frame}[allowframebreaks]{First Order Logic}
    \begin{itemize}
        \item FOL is extremely flexible and expressive;
        \item you can use recursion and define recursive structures;
        \item maybe too ``powerful'' for canonic NN.
        \begin{itemize}
            \item[$\Rightarrow$] Most NN are natively DAG (directed acyclic graph)
            \item this allows backpropagation as training algorithm but ...
            \item how can you support recursion?  
        \end{itemize}
    \end{itemize}
    \centering
    %
    \phantom{You can't!}
    %
    \phantom{Unless you use some tricks.}
    
    \framebreak
    
    \begin{itemize}
        \item FOL is extremely flexible and expressive;
        \item you can use recursion and define recursive structures;
        \item maybe too ``powerful'' for canonic NN.
        \begin{itemize}
            \item[$\Rightarrow$] Most NN are natively DAG (directed acyclic graph)
            \item this allows backpropagation as training algorithm but ...
            \item how can you support recursion?  
        \end{itemize}
    \end{itemize}
    \centering
    %
    You can't!
    %
    Unless you use some tricks.
    
    \framebreak
    
    \begin{equation*}
        \begin{aligned}
            \pred{parent}(\const{abraham},\const{isaac}). &\phantom{\rightarrow} \pred{male}(\const{abraham}).\\
            \pred{parent}(\const{sarah},\const{isaac}). &\phantom{\rightarrow} \pred{female}(\const{sarah}).\\
            \pred{parent}(\const{isaac},\const{jacob}). &\phantom{\rightarrow} \pred{male}(\const{isaac}).\\
            \pred{parent}(\const{rebekah},\const{jacob}). &\phantom{\rightarrow} \pred{female}(\const{rebekah}).\\
            \dots &\phantom{\rightarrow} \pred{male}(\const{jacob}).\\
            \forall\var{X} \forall\var{Y} \pred{parent}(\const{\var{X}},\var{Y}) &\rightarrow \pred{child}(\var{Y},\var{X}).\\
            \forall\var{X} \forall\var{Y} \pred{parent}(\const{\var{X}},\var{Y}) \wedge \pred{male}(\var{X}) &\rightarrow \pred{father}(\var{X},\var{Y}).\\
            \forall\var{X} \forall\var{Y} \pred{parent}(\const{\var{X}},\var{Y}) \wedge \pred{female}(\var{X}) &\rightarrow \pred{mother}(\var{X},\var{Y}).\\
            \forall\var{X} \forall\var{Y} \exists\var{Z} \pred{parent}(\const{\var{X}},\var{Z}) \wedge \pred{parent}(\var{Z},\var{Y}) &\rightarrow \pred{grandparent}(\var{X},\var{Y}).\\
        \end{aligned}    
    \end{equation*}
\end{frame}
%/////////

%/////////
\begin{frame}[allowframebreaks]{Knowledge Graph}
    
    \begin{itemize}
        \item Only constants, variables and n-ary predicates with $n < 3$;
        \item collections of triplets $\langle \functor{a}\ \predication{f}\ \functor{b} \rangle$ or $\predication{f}(\functor{a}, \functor{b})$
        \item essentially directed graph:
        \begin{itemize}
            \item nodes $\rightarrow$ individuals,
            \item vertices $\rightarrow$ properties connecting individuals;
        \end{itemize}
        \item may instantiate an ontology, i.e., a formal description of classes characterising a given domain.
    \end{itemize}
    
    \framebreak
    
    \begin{figure}
        \centering
        \includegraphics[width=0.8\textwidth]{figures/kg-example}
    \end{figure}    
\end{frame}    
%/////////
    
%/////////
\begin{frame}[allowframebreaks]{Propositional Logic}
    \begin{itemize}
        \item No quantifiers, terms, and non-atomic predicates;
        \item expressions involving one or many 0-ary predicates (propositions) possibly interconnected by ordinary logic connectives;
        \item low expressiveness, but easy to work with.
    \end{itemize}
    %
    \centering
    \begin{equation*}
        \begin{aligned}
            \pred{big\_petal}\wedge\pred{average\_sepal}&\rightarrow\const{virginica}.\\
            \pred{big\_petal}\wedge\neg\pred{average\_sepal}&\rightarrow\const{versicolor}.\\
            \pred{big\_petal}&\rightarrow\const{setosa}.\\
            \pred{average\_sepal}&\equiv(3\le\var{SepalWidth}<5)\\
            \pred{big\_petal}&\equiv(\var{PetalLength}>3)\\
        \end{aligned}    
    \end{equation*}
    
    \framebreak
    
    \begin{figure}
        \centering
        \includegraphics[width=0.6\textwidth]{figures/iris-dataset}
    \end{figure}

\end{frame}
%/////////

\subsection{Example Algorithms}

%/////////
\begin{frame}[allowframebreaks]{KINS: Knowledge Injection via Network Structuring}
    
    \begin{block}{KINS: Knowledge Injection via Network Structuring}
        %
        A general SKI algorithm that does not impose constrains on the sub-symbolic predictor to enrich.
        %
        \begin{itemize}
            %
            \item aim $\rightarrow$ enrich;
            %
            \item predictor $\rightarrow$ neural network;
            %
            \item how $\rightarrow$ structuring;
            %
            \item logic $\rightarrow$ stratified Datalog with negation.
            %    
        \end{itemize}        
    \end{block}

    \framebreak
    
    \begin{figure}
        \centering
        \includegraphics[width=0.8\textwidth]{figures/kins-architecture}
    \end{figure}

    \framebreak
    
    \input{tables/kins-fuzzification}
    
    \framebreak
    
    \begin{figure}
        \centering
        \includegraphics[width=0.8\textwidth]{figures/kins-fuzzifier-modules}
    \end{figure}

    % \framebreak
    
    % \lstinputlisting[
    %     language=Python,
    %     basicstyle=\ttfamily\tiny,
    %     label=lst:code,
    %     captionpos=b,
    % ]{listings/kins-snippet.py}
    
\end{frame}
%/////////

%/////////
\begin{frame}[allowframebreaks]{KILL: Knowledge Injection via Lambda Layer}
    TODO
\end{frame}
%/////////

%===============================================================================
\section{\psyki}
%===============================================================================

\begin{frame}[allowframebreaks]
\frametitle{Overall Design}

    \begin{center}
        \includegraphics[width=\linewidth]{figures/psyki-design.pdf}
    \end{center}

    \framebreak

    Key components:
    %
    \begin{description}
        \item[injectior:] todo
        %
        \begin{itemize}
            \item details here
        \end{itemize}

        \item[predictor:] some trained classifier/regressor from which knowledge should be extracted
                
        \item[formula:] 
    \end{description}

    \begin{block}{Unified API for SKI}
        \begin{itemize}
            \item 1 interface for \kt{Injector}, several implementations
            %
            \begin{itemize}
                \item[eg] KILL, KINS, etc.
            \end{itemize}
            \item 1 interface for \kt{Formula}, several implementations
            %
            \begin{itemize}
                \item[eg] FOL, Datalog, etc.
            \end{itemize}
            \item 1 interface for \kt{Predictor}, several implementations
            %
            \begin{itemize}
                \item[eg] NN, kNN, DT
            \end{itemize}
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}[allowframebreaks]
\frametitle{API Design}

    \begin{center}
        \includegraphics[width=.7\linewidth]{figures/psyki-class-diagram.pdf}
    \end{center}

    \framebreak

    Comments: TODO
\end{frame}


%===============================================================================
\section{Tutorial}
%===============================================================================

\begin{frame}{Tutorial}

    Two ways to reproduce the tutorial:
    
    \begin{block}{GitHub Repository (long way)}\centering
        \alert{\url{https://github.com/pikalab-unibo/prima-tutorial-2022}}
    \end{block}

    \begin{block}{DockerHub Images (quick way)}\centering
        \alert{\url{https://hub.docker.com/r/pikalab/prima-tutorial-2022/tags}}
    \end{block}
\end{frame}

\subsection{From GitHub}

\begin{frame}[allowframebreaks]{How to set the tutorial up from GitHub}

    \begin{block}{Enviromental pre-requisites}
        \begin{itemize}
            \item Python \alert{\texttt{3.9.x}}
            \item JDK \alert{$\geq$ \texttt{11}}
            \item Git
        \end{itemize}
    \end{block}

    \begin{enumerate}
        \item \texttt{git clone https://github.com/pikalab-unibo/prima-tutorial-2022}
        \item \texttt{cd prima-tutorial-2022}
        \item \texttt{pip install -r requirements.txt}
        \item \texttt{jupyter notebook}
        \framebreak
        \item Your browser should automatically open showing the following page:
        %
        \begin{center}
            \includegraphics[width=.7\linewidth]{figures/jupyter-git.png}
        \end{center}
        \item open the \texttt{psyki-tutorial.ipynb} notebook
        \item listen to the speaker presenting the tutorial =)
    \end{enumerate}
\end{frame}

\subsection{From DockerHub}

\begin{frame}[allowframebreaks]{How to set the tutorial up via Docker}

    \begin{block}{Enviromental pre-requisites}
        \begin{itemize}
            \item Docker
        \end{itemize}
    \end{block}

    \begin{enumerate}
        \item \texttt{DOCKER\_IMAGE=}$\begin{cases}
            \texttt{pikalab/prima-tutorial-2022:latest} & \text{on most computers}
            \\
            \texttt{pikalab/prima-tutorial-2022:latest\alert{-apple-m1}} & \text{on Apple M1 computers}
        \end{cases}$
        \item \texttt{docker pull \$DOCKER\_IMAGE}
        %
        \begin{itemize}
            \item in case of lacking Internet access:
            %
            \begin{center}\ttfamily
                docker image load -i /path/to/local/image/file.tar
            \end{center}
        \end{itemize}
        \item \texttt{docker run -it --rm --name prima-tutorial-ske-ski -p 8888:8888 \$DOCKER\_IMAGE}
        \item Some textual output such as the following one should appear:
        %
        \lstinputlisting[basicstyle=\tiny\ttfamily]{listings/docker-logs.txt}
        \framebreak
        \item Copy-paste into your browser any link of the form: 
        %
        \begin{center}
            \alert{\texttt{http://cb0a3641caf0:8888/?token=\textit{TOKEN}}}
        \end{center}
        %
        \item Your browser should now be showing the following page:
        %
        \begin{center}
            \includegraphics[width=.7\linewidth]{figures/jupyter-docker.png}
        \end{center}
        \item open the \texttt{psyki-tutorial.ipynb} notebook
        \item listen to the speaker presenting the tutorial =)
    \end{enumerate}
\end{frame}

%===============================================================================
\section{Discussion}
%===============================================================================

\begin{frame}{Notable Remarks}
    \begin{itemize}
        \item stuff
    \end{itemize}
\end{frame}

\begin{frame}{Current Limitations}
    \begin{itemize}
        \item todo
    \end{itemize}
\end{frame}

\begin{frame}{Future research activities}
    \begin{itemize}
        \item todo
    \end{itemize}
\end{frame}

%===============================================================================
\section*{}
%===============================================================================

%/////////
\frame{\titlepage}
%/////////

%===============================================================================
\section*{\refname}
%===============================================================================

%%%%
\setbeamertemplate{page number in head/foot}{}
%/////////
% \begin{frame}[c,noframenumbering]{\refname}
\begin{frame}[t,allowframebreaks,noframenumbering]{\refname}
%	\tiny
    \scriptsize
%	\footnotesize
    \bibliographystyle{apalike-AMS}
    \bibliography{psyki-tutorial}
\end{frame}
%/////////

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\end{document}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
